\fancyfoot{ }
\begin{abstract}

针对小样本问题，首先构建深层残差网络来实现Relation Network模型，并在miniImageNet数据集中实现小样本的分类，
记录分类的准确率。以此为目标，进行并行加速实验的设计与实现。

首先给出实验环境，包括：1.CPU、GPU和内存等硬件设备信息；2.操作系统和开发工具等软件及版本，并简述了各个软件负责的功能；
3.实验所需的实验参数及取值。而后分别从数据并行的方法、并行加载数据的角度出发
，阐述了本次实验中并行算法的设计思想，并对并行实现的原理进行了解析，包括多进程的工作流程和通信方法等。

而后针对并行加载数据进行对比实验，列出了在不同数量进程下的加速比与并行效率，对最终结果进行分析并得到了在进程数
和处理器核心数近似相等的情况下，加速比效果较为良好的结论；
针对DataParallel和DistributedDataParallel两种不同的并行方式，进行了对比实验后取得加速比，
并结合对并行原理的解析，得到了DistributedDataParallel优于DataParallel的结论。
之后更改实验参数，分析实验在不同参数下取得的结果并得到：
并行方法的适用场合和实验参数如何取值等相关结论。

最后，在附录中列出了实验过程中遇到的相关问题和对应的解决方案，并给出实验所用的源程序。

\end{abstract}

\textbf{关键词：} 深度学习，单机多卡，数据并行
\newpage
\fancyfoot[C]{\bfseries\thepage}